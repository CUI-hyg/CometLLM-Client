![Logo](https://avatars.githubusercontent.com/u/184814437?v=4&size=64 "CometLLM-Client")
<div align='center'> 
    <img src="https://avatars.githubusercontent.com/u/184814437?v=4&size=60">
    <font size="70"> Comet LLM Client V0.0.5-Alpha </font>
</div>

é«˜æ€§èƒ½LLMå®¢æˆ·ç«¯ï¼ŒèšåˆOpenAIå’ŒAnthropic APIï¼Œæä¾›ç»Ÿä¸€æ¥å£å’Œä¼˜åŒ–æ€§èƒ½ï¼Œä½¿å¾—å¼€å‘è€…æ— éœ€å•ç‹¬é€‚é…æœåŠ¡å•†ï¼Œå°½å¯èƒ½æé«˜æ•ˆç‡

## ç‰¹æ€§

- ğŸš€ é«˜æ€§èƒ½å¼‚æ­¥æ”¯æŒ
- ğŸ”§ ç»Ÿä¸€APIæ¥å£ï¼ˆå…¼å®¹OpenAIå’ŒAnthropicï¼‰
- ğŸ’¾ æ™ºèƒ½HTTPè¿æ¥æ± 
- ğŸ”„ è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†
- ğŸ“Š å®Œæ•´çš„ç±»å‹æç¤º
- ğŸ”’ Pydanticæ•°æ®éªŒè¯
- ğŸ› ï¸ å·¥å…·è°ƒç”¨æ”¯æŒ
- ğŸ“¡ æµå¼å“åº”æ”¯æŒ
- âœ¨ ä¼˜åŒ–çš„æ¥å£ï¼Œæ— éœ€æ‰‹åŠ¨é€‚é…æ¯ä¸ªæœåŠ¡å•†

## å®‰è£…

```bash
pip install -e .
```

## å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨OpenAI

```python
from CometLLM import CometLLM

# æ–¹æ³•1: ä½¿ç”¨å·¥å‚æ–¹æ³•
client = CometLLM.openai(api_key="your-api-key", model="gpt-4")

# æ–¹æ³•2: ä½¿ç”¨é…ç½®å­—å…¸
client = CometLLM({
    "provider": "openai",
    "api_key": "your-api-key",
    "model": "gpt-4",
    "temperature": 0.7,
})

# ç®€å•å®Œæˆ
response = client.complete("Hello, how are you?")
print(response)

# èŠå¤©å®Œæˆ
from CometLLM import Message

messages = [
    {"role": "system", "content": "You are a helpful assistant"},
    {"role": "user", "content": "What is Python?"},
]

response = client.chat(messages)
print(response.choices[0].message.content)
```

### ä½¿ç”¨Anthropic (Claude)

```python
from CometLLM import CometLLM

client = CometLLM.anthropic(api_key="your-api-key", model="claude-3-opus-20240229")

response = client.complete("Hello, how are you?")
print(response)
```

### æµå¼å“åº”

```python
# åŒæ­¥æµå¼
for chunk in client.stream([{"role": "user", "content": "Tell me a story"}]):
    content = chunk.choices[0].delta.get("content", "")
    print(content, end="", flush=True)

# å¼‚æ­¥æµå¼
async for chunk in client.astream([{"role": "user", "content": "Tell me a story"}]):
    content = chunk.choices[0].delta.get("content", "")
    print(content, end="", flush=True)
```

### å¼‚æ­¥ä½¿ç”¨

```python
import asyncio
from CometLLM import CometLLM

async def main():
    client = CometLLM.openai(api_key="your-api-key")
    
    # å¼‚æ­¥å®Œæˆ
    response = await client.acomplete("Hello!")
    print(response)
    
    # å¼‚æ­¥èŠå¤©
    response = await client.achat([
        {"role": "user", "content": "What is AI?"}
    ])
    print(response.choices[0].message.content)
    
    await client.aclose()

asyncio.run(main())
```

### å·¥å…·è°ƒç”¨

```python
from CometLLM import CometLLM, Tool, ToolFunction

client = CometLLM.openai(api_key="your-api-key", model="gpt-4")

tools = [
    Tool(
        type="function",
        function=ToolFunction(
            name="get_weather",
            description="Get weather for a location",
            parameters={
                "type": "object",
                "properties": {
                    "location": {"type": "string"},
                },
                "required": ["location"],
            },
        )
    )
]

response = client.chat(
    messages=[{"role": "user", "content": "What's the weather in Beijing?"}],
    tools=tools,
)

# æ£€æŸ¥å·¥å…·è°ƒç”¨
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        print(f"Function: {tool_call['function']['name']}")
        print(f"Arguments: {tool_call['function']['arguments']}")
```

## é…ç½®é€‰é¡¹

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `provider` | str | å¿…å¡« | æä¾›å•†: `openai` æˆ– `anthropic` |
| `api_key` | str | å¿…å¡« | APIå¯†é’¥ |
| `model` | str | å¿…å¡« | æ¨¡å‹åç§° |
| `base_url` | str | None | è‡ªå®šä¹‰APIåœ°å€ |
| `temperature` | float | 0.7 | é‡‡æ ·æ¸©åº¦ (0-2) |
| `max_tokens` | int | None | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `top_p` | float | 1.0 | æ ¸é‡‡æ ·å‚æ•° |
| `timeout` | float | 60.0 | è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) |
| `max_retries` | int | 3 | æœ€å¤§é‡è¯•æ¬¡æ•° |
| `retry_delay` | float | 1.0 | é‡è¯•å»¶è¿Ÿ(ç§’) |

## é”™è¯¯å¤„ç†

```python
from CometLLM import CometLLM
from CometLLM.exceptions import AuthenticationError, RateLimitError, APIError

client = CometLLM.openai(api_key="your-api-key")

try:
    response = client.complete("Hello")
except AuthenticationError as e:
    print(f"è®¤è¯å¤±è´¥: {e.message}")
except RateLimitError as e:
    print(f"é€Ÿç‡é™åˆ¶: {e.message}")
except APIError as e:
    print(f"APIé”™è¯¯: {e.message} (çŠ¶æ€ç : {e.status_code})")
```

## é¡¹ç›®ç»“æ„

```
CometLLM/
â”œâ”€â”€ __init__.py          # åŒ…å…¥å£
â”œâ”€â”€ client.py            # ç»Ÿä¸€å®¢æˆ·ç«¯
â”œâ”€â”€ types.py             # ç±»å‹å®šä¹‰
â”œâ”€â”€ exceptions.py        # å¼‚å¸¸å®šä¹‰
â”œâ”€â”€ base.py              # åŸºç¡€å®¢æˆ·ç«¯
â””â”€â”€ providers/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ openai.py        # OpenAIå®ç°
    â””â”€â”€ anthropic.py     # Anthropicå®ç°
```

## è®¸å¯è¯

MIT
